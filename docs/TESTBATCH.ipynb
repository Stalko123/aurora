{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenovo/miniconda3/envs/aurora/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from create_batch_era5 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aurora_to_era5_atm = {\n",
    "    't': 'temperature',\n",
    "    'u': 'u_component_of_wind',\n",
    "    'v': 'v_component_of_wind',\n",
    "    'q': 'specific_humidity',\n",
    "    'z': 'geopotential_at_surface'}\n",
    "\n",
    "aurora_to_era5_surf = {\n",
    "    '2t': '2m_temperature',\n",
    "    '10u': '10m_u_component_of_wind',\n",
    "    '10v': '10m_v_component_of_wind',\n",
    "    'swh': 'significant_height_of_combined_wind_waves_and_swell',\n",
    "    'mwd': 'mean_wave_direction',\n",
    "    'mwp': 'mean_wave_period',\n",
    "    'pp1d': 'peak_wave_period',\n",
    "    'shww': 'significant_height_of_wind_waves',\n",
    "    'shts': 'significant_height_of_total_swell',\n",
    "    'mdts': 'mean_direction_of_total_swell',\n",
    "    'mpts': 'mean_period_of_total_swell',\n",
    "    'swh1': 'significant_wave_height_of_first_swell_partition',\n",
    "    'mwd1': 'mean_wave_direction_of_first_swell_partition',\n",
    "    'mwp1': 'mean_wave_period_of_first_swell_partition',\n",
    "    'swh2': 'significant_wave_height_of_second_swell_partition',\n",
    "    'mwd2': 'mean_wave_direction_of_second_swell_partition',\n",
    "    'mwp2': 'mean_wave_period_of_second_swell_partition',\n",
    "    '10u_wave': 'u_component_stokes_drift',\n",
    "    '10v_wave': 'v_component_stokes_drift',\n",
    "    'wind': 'ocean_surface_stress_equivalent_10m_neutral_wind_speed',\n",
    "}\n",
    "\n",
    "aurora_to_era5 = {'2t': '2m_temperature',\n",
    "    '10u': '10m_u_component_of_wind',\n",
    "    '10v': '10m_v_component_of_wind',\n",
    "    'swh': 'significant_height_of_combined_wind_waves_and_swell',\n",
    "    'mwd': 'mean_wave_direction',\n",
    "    'mwp': 'mean_wave_period',\n",
    "    'pp1d': 'peak_wave_period',\n",
    "    'shww': 'significant_height_of_wind_waves',\n",
    "    'shts': 'significant_height_of_total_swell',\n",
    "    'mdts': 'mean_direction_of_total_swell',\n",
    "    'mpts': 'mean_period_of_total_swell',\n",
    "    'swh1': 'significant_wave_height_of_first_swell_partition',\n",
    "    'mwd1': 'mean_wave_direction_of_first_swell_partition',\n",
    "    'mwp1': 'mean_wave_period_of_first_swell_partition',\n",
    "    'swh2': 'significant_wave_height_of_second_swell_partition',\n",
    "    'mwd2': 'mean_wave_direction_of_second_swell_partition',\n",
    "    'mwp2': 'mean_wave_period_of_second_swell_partition',\n",
    "    '10u_wave': 'u_component_stokes_drift',\n",
    "    '10v_wave': 'v_component_stokes_drift',\n",
    "    'wind': 'ocean_surface_stress_equivalent_10m_neutral_wind_speed','t': 'temperature',\n",
    "    'u': 'u_component_of_wind',\n",
    "    'v': 'v_component_of_wind',\n",
    "    'q': 'specific_humidity',\n",
    "    'z': 'geopotential_at_surface',\n",
    "    'slt': 'soil_type',\n",
    "    'lsm' :'land_sea_mask'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3\"\n",
    "year = 2020\n",
    "month = 1\n",
    "day = 1\n",
    "hour_start = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 721, 1440)\n",
      "('time', 'level', 'latitude', 'longitude')\n",
      "(2, 1, 721, 1440)\n",
      "('time', 'level', 'latitude', 'longitude')\n",
      "(2, 1, 721, 1440)\n",
      "('time', 'level', 'latitude', 'longitude')\n",
      "(2, 1, 721, 1440)\n",
      "('time', 'level', 'latitude', 'longitude')\n",
      "z: (2, 1, 721, 1440)\n",
      "torch.Size([721, 1440])\n"
     ]
    }
   ],
   "source": [
    "batch= get_batch_era5(path, year, month, day, hour_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(surf_vars={'2t': tensor([[[[246.4584, 246.4584, 246.4584,  ..., 246.4584, 246.4584, 246.4584],\n",
       "          [246.6830, 246.6769, 246.6723,  ..., 246.6938, 246.6907, 246.6861],\n",
       "          [247.1170, 247.1078, 247.0985,  ..., 247.1401, 247.1293, 247.1216],\n",
       "          ...,\n",
       "          [246.7307, 246.7307, 246.7307,  ..., 246.7292, 246.7307, 246.7307],\n",
       "          [246.2906, 246.2906, 246.2922,  ..., 246.2906, 246.2906, 246.2906],\n",
       "          [245.8629, 245.8629, 245.8629,  ..., 245.8629, 245.8629, 245.8629]],\n",
       "\n",
       "         [[246.3214, 246.3214, 246.3214,  ..., 246.3214, 246.3214, 246.3214],\n",
       "          [246.8692, 246.8646, 246.8600,  ..., 246.8769, 246.8739, 246.8723],\n",
       "          [247.4755, 247.4725, 247.4663,  ..., 247.4801, 247.4755, 247.4740],\n",
       "          ...,\n",
       "          [246.1752, 246.1768, 246.1814,  ..., 246.1691, 246.1737, 246.1752],\n",
       "          [245.8475, 245.8475, 245.8490,  ..., 245.8428, 245.8444, 245.8444],\n",
       "          [245.4520, 245.4520, 245.4520,  ..., 245.4520, 245.4520, 245.4520]]]]), '10u': tensor([[[[-0.7197, -0.7197, -0.7197,  ..., -0.7197, -0.7197, -0.7197],\n",
       "          [-4.3020, -4.2952, -4.2883,  ..., -4.3157, -4.3104, -4.3066],\n",
       "          [-3.6004, -3.5959, -3.5860,  ..., -3.6187, -3.6095, -3.6035],\n",
       "          ...,\n",
       "          [-3.6741, -3.6786, -3.6847,  ..., -3.6498, -3.6597, -3.6680],\n",
       "          [-4.0742, -4.0773, -4.0795,  ..., -4.0590, -4.0636, -4.0681],\n",
       "          [ 0.2180,  0.2180,  0.2180,  ...,  0.2180,  0.2180,  0.2180]],\n",
       "\n",
       "         [[-0.9201, -0.9201, -0.9201,  ..., -0.9201, -0.9201, -0.9201],\n",
       "          [-0.7903, -0.7956, -0.8002,  ..., -0.7751, -0.7797, -0.7858],\n",
       "          [ 0.1360,  0.1178,  0.1041,  ...,  0.1793,  0.1687,  0.1550],\n",
       "          ...,\n",
       "          [-3.6543, -3.6536, -3.6521,  ..., -3.6460, -3.6498, -3.6528],\n",
       "          [-4.2496, -4.2481, -4.2473,  ..., -4.2428, -4.2458, -4.2473],\n",
       "          [ 0.3904,  0.3904,  0.3904,  ...,  0.3904,  0.3904,  0.3904]]]]), '10v': tensor([[[[-0.2908, -0.2908, -0.2908,  ..., -0.2908, -0.2908, -0.2908],\n",
       "          [ 2.9826,  2.9884,  2.9942,  ...,  2.9568,  2.9660,  2.9743],\n",
       "          [ 2.8920,  2.8978,  2.9061,  ...,  2.8562,  2.8728,  2.8861],\n",
       "          ...,\n",
       "          [ 1.3596,  1.3447,  1.3272,  ...,  1.4020,  1.3854,  1.3713],\n",
       "          [ 1.4012,  1.3904,  1.3796,  ...,  1.4278,  1.4187,  1.4104],\n",
       "          [-0.0480, -0.0480, -0.0480,  ..., -0.0480, -0.0480, -0.0480]],\n",
       "\n",
       "         [[-0.2392, -0.2392, -0.2392,  ..., -0.2392, -0.2392, -0.2392],\n",
       "          [-0.0621, -0.0638, -0.0654,  ..., -0.0530, -0.0563, -0.0588],\n",
       "          [-0.5909, -0.5942, -0.5984,  ..., -0.5710, -0.5768, -0.5834],\n",
       "          ...,\n",
       "          [-0.1128, -0.1295, -0.1494,  ..., -0.0546, -0.0771, -0.0970],\n",
       "          [ 0.3436,  0.3320,  0.3187,  ...,  0.3769,  0.3661,  0.3544],\n",
       "          [-0.1403, -0.1403, -0.1403,  ..., -0.1403, -0.1403, -0.1403]]]]), 'mdww': tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]]), 'mpww': tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]]), 'swh': tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]]), 'mwd': tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]]), 'mwp': tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]]), 'pp1d': tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]]), 'shww': tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]]), 'shts': tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]]), 'mdts': tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]]), 'mpts': tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]]), 'swh1': tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]]), 'mwd1': tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]]), 'mwp1': tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]]), 'swh2': tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]]), 'mwd2': tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]]), 'mwp2': tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]]), '10u_wave': tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]]), '10v_wave': tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]]), 'wind': tensor([[[[5.3449, 5.3449, 5.3449,  ..., 5.3449, 5.3449, 5.3449],\n",
       "          [5.1217, 5.3449, 5.1217,  ..., 5.3449, 5.1217, 5.3449],\n",
       "          [5.1217, 5.1217, 5.1217,  ..., 5.1217, 5.1217, 5.1217],\n",
       "          ...,\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan]],\n",
       "\n",
       "         [[2.0249, 2.0249, 2.0249,  ..., 2.0249, 2.0249, 2.0249],\n",
       "          [2.0000, 2.0249, 2.0000,  ..., 2.0249, 2.0000, 2.0249],\n",
       "          [2.0000, 2.0000, 2.0000,  ..., 2.0000, 2.0000, 2.0000],\n",
       "          ...,\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan]]]])}, static_vars={'lsm': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]])}, atmos_vars={'t': tensor([[[[[264.9522, 264.9522, 264.9522,  ..., 264.9522, 264.9522,\n",
       "            264.9522],\n",
       "           [264.8228, 264.8253, 264.8265,  ..., 264.8155, 264.8167,\n",
       "            264.8192],\n",
       "           [264.4348, 264.4384, 264.4421,  ..., 264.4201, 264.4262,\n",
       "            264.4299],\n",
       "           ...,\n",
       "           [289.3661, 289.3685, 289.3697,  ..., 289.3636, 289.3636,\n",
       "            289.3661],\n",
       "           [289.3295, 289.3295, 289.3295,  ..., 289.3295, 289.3295,\n",
       "            289.3295],\n",
       "           [289.2221, 289.2221, 289.2221,  ..., 289.2221, 289.2221,\n",
       "            289.2221]]],\n",
       "\n",
       "\n",
       "         [[[272.9811, 272.9811, 272.9811,  ..., 272.9811, 272.9811,\n",
       "            272.9811],\n",
       "           [273.2252, 273.2277, 273.2277,  ..., 273.2216, 273.2228,\n",
       "            273.2228],\n",
       "           [273.2972, 273.3009, 273.3033,  ..., 273.2899, 273.2911,\n",
       "            273.2960],\n",
       "           ...,\n",
       "           [290.0007, 290.0031, 290.0043,  ..., 289.9946, 289.9970,\n",
       "            289.9982],\n",
       "           [289.7920, 289.7920, 289.7932,  ..., 289.7871, 289.7896,\n",
       "            289.7896],\n",
       "           [289.5650, 289.5650, 289.5650,  ..., 289.5650, 289.5650,\n",
       "            289.5650]]]]]), 'u': tensor([[[[[ 9.1553e-04,  9.1553e-04,  9.1553e-04,  ...,  9.1553e-04,\n",
       "             9.1553e-04,  9.1553e-04],\n",
       "           [-7.2858e+01, -7.2930e+01, -7.3001e+01,  ..., -7.2642e+01,\n",
       "            -7.2719e+01, -7.2791e+01],\n",
       "           [-7.1071e+01, -7.1133e+01, -7.1189e+01,  ..., -7.0891e+01,\n",
       "            -7.0953e+01, -7.1015e+01],\n",
       "           ...,\n",
       "           [-5.8366e+00, -5.8366e+00, -5.8263e+00,  ..., -5.8417e+00,\n",
       "            -5.8417e+00, -5.8417e+00],\n",
       "           [-5.1743e+00, -5.1640e+00, -5.1640e+00,  ..., -5.1794e+00,\n",
       "            -5.1794e+00, -5.1743e+00],\n",
       "           [ 9.1553e-04,  9.1553e-04,  9.1553e-04,  ...,  9.1553e-04,\n",
       "             9.1553e-04,  9.1553e-04]]],\n",
       "\n",
       "\n",
       "         [[[ 9.1553e-04,  9.1553e-04,  9.1553e-04,  ...,  9.1553e-04,\n",
       "             9.1553e-04,  9.1553e-04],\n",
       "           [-6.1650e+01, -6.1711e+01, -6.1773e+01,  ..., -6.1445e+01,\n",
       "            -6.1516e+01, -6.1578e+01],\n",
       "           [-6.0603e+01, -6.0664e+01, -6.0721e+01,  ..., -6.0407e+01,\n",
       "            -6.0469e+01, -6.0541e+01],\n",
       "           ...,\n",
       "           [-5.8007e+00, -5.7596e+00, -5.7134e+00,  ..., -5.9290e+00,\n",
       "            -5.8828e+00, -5.8469e+00],\n",
       "           [-4.6198e+00, -4.5787e+00, -4.5325e+00,  ..., -4.7533e+00,\n",
       "            -4.7071e+00, -4.6660e+00],\n",
       "           [ 9.1553e-04,  9.1553e-04,  9.1553e-04,  ...,  9.1553e-04,\n",
       "             9.1553e-04,  9.1553e-04]]]]]), 'v': tensor([[[[[-1.8922e-03, -1.8922e-03, -1.8922e-03,  ..., -1.8922e-03,\n",
       "            -1.8922e-03, -1.8922e-03],\n",
       "           [-1.7824e+01, -1.7493e+01, -1.7176e+01,  ..., -1.8793e+01,\n",
       "            -1.8462e+01, -1.8141e+01],\n",
       "           [-1.6434e+01, -1.6113e+01, -1.5791e+01,  ..., -1.7394e+01,\n",
       "            -1.7072e+01, -1.6751e+01],\n",
       "           ...,\n",
       "           [-1.1743e+00, -1.1979e+00, -1.2215e+00,  ..., -1.1128e+00,\n",
       "            -1.1365e+00, -1.1601e+00],\n",
       "           [-1.2074e+00, -1.2310e+00, -1.2452e+00,  ..., -1.1412e+00,\n",
       "            -1.1648e+00, -1.1885e+00],\n",
       "           [-1.8922e-03, -1.8922e-03, -1.8922e-03,  ..., -1.8922e-03,\n",
       "            -1.8922e-03, -1.8922e-03]]],\n",
       "\n",
       "\n",
       "         [[[ 2.8351e-03,  2.8351e-03,  2.8351e-03,  ...,  2.8351e-03,\n",
       "             2.8351e-03,  2.8351e-03],\n",
       "           [-1.4945e+01, -1.4680e+01, -1.4411e+01,  ..., -1.5749e+01,\n",
       "            -1.5479e+01, -1.5214e+01],\n",
       "           [-1.4264e+01, -1.4004e+01, -1.3740e+01,  ..., -1.5049e+01,\n",
       "            -1.4789e+01, -1.4529e+01],\n",
       "           ...,\n",
       "           [-9.9955e+00, -1.0010e+01, -1.0029e+01,  ..., -9.9388e+00,\n",
       "            -9.9577e+00, -9.9766e+00],\n",
       "           [-9.7969e+00, -9.8111e+00, -9.8253e+00,  ..., -9.7449e+00,\n",
       "            -9.7591e+00, -9.7828e+00],\n",
       "           [ 2.8351e-03,  2.8351e-03,  2.8351e-03,  ...,  2.8351e-03,\n",
       "             2.8351e-03,  2.8351e-03]]]]]), 'q': tensor([[[[[3.9158e-06, 3.9158e-06, 3.9158e-06,  ..., 3.9158e-06,\n",
       "            3.9158e-06, 3.9158e-06],\n",
       "           [3.9018e-06, 3.9018e-06, 3.9018e-06,  ..., 3.9018e-06,\n",
       "            3.9018e-06, 3.9018e-06],\n",
       "           [3.8922e-06, 3.8921e-06, 3.8920e-06,  ..., 3.8923e-06,\n",
       "            3.8923e-06, 3.8922e-06],\n",
       "           ...,\n",
       "           [3.9631e-06, 3.9631e-06, 3.9631e-06,  ..., 3.9630e-06,\n",
       "            3.9630e-06, 3.9630e-06],\n",
       "           [3.9641e-06, 3.9641e-06, 3.9641e-06,  ..., 3.9640e-06,\n",
       "            3.9641e-06, 3.9641e-06],\n",
       "           [3.9642e-06, 3.9642e-06, 3.9642e-06,  ..., 3.9642e-06,\n",
       "            3.9642e-06, 3.9642e-06]]],\n",
       "\n",
       "\n",
       "         [[[3.7864e-06, 3.7864e-06, 3.7864e-06,  ..., 3.7864e-06,\n",
       "            3.7864e-06, 3.7864e-06],\n",
       "           [3.7909e-06, 3.7909e-06, 3.7910e-06,  ..., 3.7909e-06,\n",
       "            3.7909e-06, 3.7909e-06],\n",
       "           [3.7892e-06, 3.7892e-06, 3.7892e-06,  ..., 3.7891e-06,\n",
       "            3.7891e-06, 3.7891e-06],\n",
       "           ...,\n",
       "           [3.9657e-06, 3.9657e-06, 3.9657e-06,  ..., 3.9657e-06,\n",
       "            3.9657e-06, 3.9657e-06],\n",
       "           [3.9651e-06, 3.9651e-06, 3.9651e-06,  ..., 3.9651e-06,\n",
       "            3.9651e-06, 3.9651e-06],\n",
       "           [3.9647e-06, 3.9647e-06, 3.9647e-06,  ..., 3.9647e-06,\n",
       "            3.9647e-06, 3.9647e-06]]]]]), 'z': tensor([[[[[-7.6172e-02, -7.6172e-02, -7.6172e-02,  ..., -7.6172e-02,\n",
       "            -7.6172e-02, -7.6172e-02],\n",
       "           [ 4.4121e+00,  4.4121e+00,  4.4121e+00,  ...,  4.4121e+00,\n",
       "             4.4121e+00,  4.4121e+00],\n",
       "           [-1.8730e+00, -1.8730e+00, -1.8730e+00,  ..., -1.8730e+00,\n",
       "            -1.8730e+00, -1.8730e+00],\n",
       "           ...,\n",
       "           [ 2.6958e+04,  2.6961e+04,  2.6965e+04,  ...,  2.6950e+04,\n",
       "             2.6952e+04,  2.6956e+04],\n",
       "           [ 2.7163e+04,  2.7165e+04,  2.7167e+04,  ...,  2.7159e+04,\n",
       "             2.7160e+04,  2.7162e+04],\n",
       "           [ 2.7355e+04,  2.7355e+04,  2.7355e+04,  ...,  2.7355e+04,\n",
       "             2.7355e+04,  2.7355e+04]]],\n",
       "\n",
       "\n",
       "         [[[-7.6172e-02, -7.6172e-02, -7.6172e-02,  ..., -7.6172e-02,\n",
       "            -7.6172e-02, -7.6172e-02],\n",
       "           [ 4.4121e+00,  4.4121e+00,  4.4121e+00,  ...,  4.4121e+00,\n",
       "             4.4121e+00,  4.4121e+00],\n",
       "           [-1.8730e+00, -1.8730e+00, -1.8730e+00,  ..., -1.8730e+00,\n",
       "            -1.8730e+00, -1.8730e+00],\n",
       "           ...,\n",
       "           [ 2.6958e+04,  2.6961e+04,  2.6965e+04,  ...,  2.6950e+04,\n",
       "             2.6952e+04,  2.6956e+04],\n",
       "           [ 2.7163e+04,  2.7165e+04,  2.7167e+04,  ...,  2.7159e+04,\n",
       "             2.7160e+04,  2.7162e+04],\n",
       "           [ 2.7355e+04,  2.7355e+04,  2.7355e+04,  ...,  2.7355e+04,\n",
       "             2.7355e+04,  2.7355e+04]]]]])}, metadata=Metadata(lat=tensor([ 90.0000,  89.7500,  89.5000,  89.2500,  89.0000,  88.7500,  88.5000,\n",
       "         88.2500,  88.0000,  87.7500,  87.5000,  87.2500,  87.0000,  86.7500,\n",
       "         86.5000,  86.2500,  86.0000,  85.7500,  85.5000,  85.2500,  85.0000,\n",
       "         84.7500,  84.5000,  84.2500,  84.0000,  83.7500,  83.5000,  83.2500,\n",
       "         83.0000,  82.7500,  82.5000,  82.2500,  82.0000,  81.7500,  81.5000,\n",
       "         81.2500,  81.0000,  80.7500,  80.5000,  80.2500,  80.0000,  79.7500,\n",
       "         79.5000,  79.2500,  79.0000,  78.7500,  78.5000,  78.2500,  78.0000,\n",
       "         77.7500,  77.5000,  77.2500,  77.0000,  76.7500,  76.5000,  76.2500,\n",
       "         76.0000,  75.7500,  75.5000,  75.2500,  75.0000,  74.7500,  74.5000,\n",
       "         74.2500,  74.0000,  73.7500,  73.5000,  73.2500,  73.0000,  72.7500,\n",
       "         72.5000,  72.2500,  72.0000,  71.7500,  71.5000,  71.2500,  71.0000,\n",
       "         70.7500,  70.5000,  70.2500,  70.0000,  69.7500,  69.5000,  69.2500,\n",
       "         69.0000,  68.7500,  68.5000,  68.2500,  68.0000,  67.7500,  67.5000,\n",
       "         67.2500,  67.0000,  66.7500,  66.5000,  66.2500,  66.0000,  65.7500,\n",
       "         65.5000,  65.2500,  65.0000,  64.7500,  64.5000,  64.2500,  64.0000,\n",
       "         63.7500,  63.5000,  63.2500,  63.0000,  62.7500,  62.5000,  62.2500,\n",
       "         62.0000,  61.7500,  61.5000,  61.2500,  61.0000,  60.7500,  60.5000,\n",
       "         60.2500,  60.0000,  59.7500,  59.5000,  59.2500,  59.0000,  58.7500,\n",
       "         58.5000,  58.2500,  58.0000,  57.7500,  57.5000,  57.2500,  57.0000,\n",
       "         56.7500,  56.5000,  56.2500,  56.0000,  55.7500,  55.5000,  55.2500,\n",
       "         55.0000,  54.7500,  54.5000,  54.2500,  54.0000,  53.7500,  53.5000,\n",
       "         53.2500,  53.0000,  52.7500,  52.5000,  52.2500,  52.0000,  51.7500,\n",
       "         51.5000,  51.2500,  51.0000,  50.7500,  50.5000,  50.2500,  50.0000,\n",
       "         49.7500,  49.5000,  49.2500,  49.0000,  48.7500,  48.5000,  48.2500,\n",
       "         48.0000,  47.7500,  47.5000,  47.2500,  47.0000,  46.7500,  46.5000,\n",
       "         46.2500,  46.0000,  45.7500,  45.5000,  45.2500,  45.0000,  44.7500,\n",
       "         44.5000,  44.2500,  44.0000,  43.7500,  43.5000,  43.2500,  43.0000,\n",
       "         42.7500,  42.5000,  42.2500,  42.0000,  41.7500,  41.5000,  41.2500,\n",
       "         41.0000,  40.7500,  40.5000,  40.2500,  40.0000,  39.7500,  39.5000,\n",
       "         39.2500,  39.0000,  38.7500,  38.5000,  38.2500,  38.0000,  37.7500,\n",
       "         37.5000,  37.2500,  37.0000,  36.7500,  36.5000,  36.2500,  36.0000,\n",
       "         35.7500,  35.5000,  35.2500,  35.0000,  34.7500,  34.5000,  34.2500,\n",
       "         34.0000,  33.7500,  33.5000,  33.2500,  33.0000,  32.7500,  32.5000,\n",
       "         32.2500,  32.0000,  31.7500,  31.5000,  31.2500,  31.0000,  30.7500,\n",
       "         30.5000,  30.2500,  30.0000,  29.7500,  29.5000,  29.2500,  29.0000,\n",
       "         28.7500,  28.5000,  28.2500,  28.0000,  27.7500,  27.5000,  27.2500,\n",
       "         27.0000,  26.7500,  26.5000,  26.2500,  26.0000,  25.7500,  25.5000,\n",
       "         25.2500,  25.0000,  24.7500,  24.5000,  24.2500,  24.0000,  23.7500,\n",
       "         23.5000,  23.2500,  23.0000,  22.7500,  22.5000,  22.2500,  22.0000,\n",
       "         21.7500,  21.5000,  21.2500,  21.0000,  20.7500,  20.5000,  20.2500,\n",
       "         20.0000,  19.7500,  19.5000,  19.2500,  19.0000,  18.7500,  18.5000,\n",
       "         18.2500,  18.0000,  17.7500,  17.5000,  17.2500,  17.0000,  16.7500,\n",
       "         16.5000,  16.2500,  16.0000,  15.7500,  15.5000,  15.2500,  15.0000,\n",
       "         14.7500,  14.5000,  14.2500,  14.0000,  13.7500,  13.5000,  13.2500,\n",
       "         13.0000,  12.7500,  12.5000,  12.2500,  12.0000,  11.7500,  11.5000,\n",
       "         11.2500,  11.0000,  10.7500,  10.5000,  10.2500,  10.0000,   9.7500,\n",
       "          9.5000,   9.2500,   9.0000,   8.7500,   8.5000,   8.2500,   8.0000,\n",
       "          7.7500,   7.5000,   7.2500,   7.0000,   6.7500,   6.5000,   6.2500,\n",
       "          6.0000,   5.7500,   5.5000,   5.2500,   5.0000,   4.7500,   4.5000,\n",
       "          4.2500,   4.0000,   3.7500,   3.5000,   3.2500,   3.0000,   2.7500,\n",
       "          2.5000,   2.2500,   2.0000,   1.7500,   1.5000,   1.2500,   1.0000,\n",
       "          0.7500,   0.5000,   0.2500,   0.0000,  -0.2500,  -0.5000,  -0.7500,\n",
       "         -1.0000,  -1.2500,  -1.5000,  -1.7500,  -2.0000,  -2.2500,  -2.5000,\n",
       "         -2.7500,  -3.0000,  -3.2500,  -3.5000,  -3.7500,  -4.0000,  -4.2500,\n",
       "         -4.5000,  -4.7500,  -5.0000,  -5.2500,  -5.5000,  -5.7500,  -6.0000,\n",
       "         -6.2500,  -6.5000,  -6.7500,  -7.0000,  -7.2500,  -7.5000,  -7.7500,\n",
       "         -8.0000,  -8.2500,  -8.5000,  -8.7500,  -9.0000,  -9.2500,  -9.5000,\n",
       "         -9.7500, -10.0000, -10.2500, -10.5000, -10.7500, -11.0000, -11.2500,\n",
       "        -11.5000, -11.7500, -12.0000, -12.2500, -12.5000, -12.7500, -13.0000,\n",
       "        -13.2500, -13.5000, -13.7500, -14.0000, -14.2500, -14.5000, -14.7500,\n",
       "        -15.0000, -15.2500, -15.5000, -15.7500, -16.0000, -16.2500, -16.5000,\n",
       "        -16.7500, -17.0000, -17.2500, -17.5000, -17.7500, -18.0000, -18.2500,\n",
       "        -18.5000, -18.7500, -19.0000, -19.2500, -19.5000, -19.7500, -20.0000,\n",
       "        -20.2500, -20.5000, -20.7500, -21.0000, -21.2500, -21.5000, -21.7500,\n",
       "        -22.0000, -22.2500, -22.5000, -22.7500, -23.0000, -23.2500, -23.5000,\n",
       "        -23.7500, -24.0000, -24.2500, -24.5000, -24.7500, -25.0000, -25.2500,\n",
       "        -25.5000, -25.7500, -26.0000, -26.2500, -26.5000, -26.7500, -27.0000,\n",
       "        -27.2500, -27.5000, -27.7500, -28.0000, -28.2500, -28.5000, -28.7500,\n",
       "        -29.0000, -29.2500, -29.5000, -29.7500, -30.0000, -30.2500, -30.5000,\n",
       "        -30.7500, -31.0000, -31.2500, -31.5000, -31.7500, -32.0000, -32.2500,\n",
       "        -32.5000, -32.7500, -33.0000, -33.2500, -33.5000, -33.7500, -34.0000,\n",
       "        -34.2500, -34.5000, -34.7500, -35.0000, -35.2500, -35.5000, -35.7500,\n",
       "        -36.0000, -36.2500, -36.5000, -36.7500, -37.0000, -37.2500, -37.5000,\n",
       "        -37.7500, -38.0000, -38.2500, -38.5000, -38.7500, -39.0000, -39.2500,\n",
       "        -39.5000, -39.7500, -40.0000, -40.2500, -40.5000, -40.7500, -41.0000,\n",
       "        -41.2500, -41.5000, -41.7500, -42.0000, -42.2500, -42.5000, -42.7500,\n",
       "        -43.0000, -43.2500, -43.5000, -43.7500, -44.0000, -44.2500, -44.5000,\n",
       "        -44.7500, -45.0000, -45.2500, -45.5000, -45.7500, -46.0000, -46.2500,\n",
       "        -46.5000, -46.7500, -47.0000, -47.2500, -47.5000, -47.7500, -48.0000,\n",
       "        -48.2500, -48.5000, -48.7500, -49.0000, -49.2500, -49.5000, -49.7500,\n",
       "        -50.0000, -50.2500, -50.5000, -50.7500, -51.0000, -51.2500, -51.5000,\n",
       "        -51.7500, -52.0000, -52.2500, -52.5000, -52.7500, -53.0000, -53.2500,\n",
       "        -53.5000, -53.7500, -54.0000, -54.2500, -54.5000, -54.7500, -55.0000,\n",
       "        -55.2500, -55.5000, -55.7500, -56.0000, -56.2500, -56.5000, -56.7500,\n",
       "        -57.0000, -57.2500, -57.5000, -57.7500, -58.0000, -58.2500, -58.5000,\n",
       "        -58.7500, -59.0000, -59.2500, -59.5000, -59.7500, -60.0000, -60.2500,\n",
       "        -60.5000, -60.7500, -61.0000, -61.2500, -61.5000, -61.7500, -62.0000,\n",
       "        -62.2500, -62.5000, -62.7500, -63.0000, -63.2500, -63.5000, -63.7500,\n",
       "        -64.0000, -64.2500, -64.5000, -64.7500, -65.0000, -65.2500, -65.5000,\n",
       "        -65.7500, -66.0000, -66.2500, -66.5000, -66.7500, -67.0000, -67.2500,\n",
       "        -67.5000, -67.7500, -68.0000, -68.2500, -68.5000, -68.7500, -69.0000,\n",
       "        -69.2500, -69.5000, -69.7500, -70.0000, -70.2500, -70.5000, -70.7500,\n",
       "        -71.0000, -71.2500, -71.5000, -71.7500, -72.0000, -72.2500, -72.5000,\n",
       "        -72.7500, -73.0000, -73.2500, -73.5000, -73.7500, -74.0000, -74.2500,\n",
       "        -74.5000, -74.7500, -75.0000, -75.2500, -75.5000, -75.7500, -76.0000,\n",
       "        -76.2500, -76.5000, -76.7500, -77.0000, -77.2500, -77.5000, -77.7500,\n",
       "        -78.0000, -78.2500, -78.5000, -78.7500, -79.0000, -79.2500, -79.5000,\n",
       "        -79.7500, -80.0000, -80.2500, -80.5000, -80.7500, -81.0000, -81.2500,\n",
       "        -81.5000, -81.7500, -82.0000, -82.2500, -82.5000, -82.7500, -83.0000,\n",
       "        -83.2500, -83.5000, -83.7500, -84.0000, -84.2500, -84.5000, -84.7500,\n",
       "        -85.0000, -85.2500, -85.5000, -85.7500, -86.0000, -86.2500, -86.5000,\n",
       "        -86.7500, -87.0000, -87.2500, -87.5000, -87.7500, -88.0000, -88.2500,\n",
       "        -88.5000, -88.7500, -89.0000, -89.2500, -89.5000, -89.7500, -90.0000]), lon=tensor([0.0000e+00, 2.5000e-01, 5.0000e-01,  ..., 3.5925e+02, 3.5950e+02,\n",
       "        3.5975e+02]), time=(datetime.datetime(2020, 1, 1, 6, 0),), atmos_levels=(50,), rollout_step=0))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available surface variables: ['2t', '10u', '10v', 'mdww', 'mpww', 'swh', 'mwd', 'mwp', 'pp1d', 'shww', 'shts', 'mdts', 'mpts', 'swh1', 'mwd1', 'mwp1', 'swh2', 'mwd2', 'mwp2', '10u_wave', '10v_wave', 'wind']\n"
     ]
    }
   ],
   "source": [
    "print(\"Available surface variables:\", list(batch.surf_vars.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available atmospheric variables: ['t', 'u', 'v', 'q', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(\"Available atmospheric variables:\", list(batch.atmos_vars.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aurora import AuroraWave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AuroraWave()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AuroraWave(\n",
       "  (encoder): Perceiver3DEncoder(\n",
       "    (surf_mlp): MLP(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (3): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (surf_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (pos_embed): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (scale_embed): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (lead_time_embed): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (absolute_time_embed): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (atmos_levels_embed): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (surf_token_embeds): LevelPatchEmbed(\n",
       "      (weights): ParameterDict(\n",
       "          (10u): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (10u_wave): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (10u_wave_density): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (10v): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (10v_wave): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (10v_wave_density): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (2t): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (lat_mask): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (lsm): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mdts_cos): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mdts_density): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mdts_sin): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mdww_cos): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mdww_density): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mdww_sin): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mpts): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mpts_density): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mpww): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mpww_density): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (msl): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mwd1_cos): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mwd1_density): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mwd1_sin): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mwd2_cos): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mwd2_density): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mwd2_sin): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mwd_cos): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mwd_density): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mwd_sin): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mwp): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mwp1): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mwp1_density): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mwp2): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mwp2_density): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (mwp_density): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (pp1d): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (pp1d_density): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (shts): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (shts_density): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (shww): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (shww_density): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (slt): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (swh): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (swh1): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (swh1_density): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (swh2): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (swh2_density): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (swh_density): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (wind): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (wind_density): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (wmb): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (z): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "      )\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (atmos_token_embeds): LevelPatchEmbed(\n",
       "      (weights): ParameterDict(\n",
       "          (q): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (t): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (u): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (v): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "          (z): Parameter containing: [torch.FloatTensor of size 512x1x2x4x4]\n",
       "      )\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (level_agg): PerceiverResampler(\n",
       "      (layers): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): PerceiverAttention(\n",
       "            (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (ln_k): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (ln_q): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): MLP(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (3): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2-3): 2 x LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (backbone): Swin3DTransformerBackbone(\n",
       "    (time_mlp): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (encoder_layers): ModuleList(\n",
       "      (0): Basic3DEncoderLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0-5): 6 x Swin3DTransformerBlock(\n",
       "            (norm1): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(2, 6, 12), num_heads=8\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (lora_proj): LoRARollout(\n",
       "                (loras): ModuleList(\n",
       "                  (0): LoRA(\n",
       "                    (lora_dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (lora_qkv): LoRARollout(\n",
       "                (loras): ModuleList(\n",
       "                  (0): LoRA(\n",
       "                    (lora_dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (mlp): MLP(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging3D(\n",
       "          (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Basic3DEncoderLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0-9): 10 x Swin3DTransformerBlock(\n",
       "            (norm1): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn): WindowAttention(\n",
       "              dim=1024, window_size=(2, 6, 12), num_heads=16\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (lora_proj): LoRARollout(\n",
       "                (loras): ModuleList(\n",
       "                  (0): LoRA(\n",
       "                    (lora_dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (lora_qkv): LoRARollout(\n",
       "                (loras): ModuleList(\n",
       "                  (0): LoRA(\n",
       "                    (lora_dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (mlp): MLP(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging3D(\n",
       "          (reduction): Linear(in_features=4096, out_features=2048, bias=False)\n",
       "          (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Basic3DEncoderLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0-7): 8 x Swin3DTransformerBlock(\n",
       "            (norm1): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn): WindowAttention(\n",
       "              dim=2048, window_size=(2, 6, 12), num_heads=32\n",
       "              (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "              (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (lora_proj): LoRARollout(\n",
       "                (loras): ModuleList(\n",
       "                  (0): LoRA(\n",
       "                    (lora_dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (lora_qkv): LoRARollout(\n",
       "                (loras): ModuleList(\n",
       "                  (0): LoRA(\n",
       "                    (lora_dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (mlp): MLP(\n",
       "              (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder_layers): ModuleList(\n",
       "      (0): Basic3DDecoderLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0-7): 8 x Swin3DTransformerBlock(\n",
       "            (norm1): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn): WindowAttention(\n",
       "              dim=2048, window_size=(2, 6, 12), num_heads=32\n",
       "              (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "              (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (lora_proj): LoRARollout(\n",
       "                (loras): ModuleList(\n",
       "                  (0): LoRA(\n",
       "                    (lora_dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (lora_qkv): LoRARollout(\n",
       "                (loras): ModuleList(\n",
       "                  (0): LoRA(\n",
       "                    (lora_dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (mlp): MLP(\n",
       "              (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (upsample): PatchSplitting3D(\n",
       "          (lin1): Linear(in_features=2048, out_features=4096, bias=False)\n",
       "          (lin2): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Basic3DDecoderLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0-9): 10 x Swin3DTransformerBlock(\n",
       "            (norm1): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn): WindowAttention(\n",
       "              dim=1024, window_size=(2, 6, 12), num_heads=16\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (lora_proj): LoRARollout(\n",
       "                (loras): ModuleList(\n",
       "                  (0): LoRA(\n",
       "                    (lora_dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (lora_qkv): LoRARollout(\n",
       "                (loras): ModuleList(\n",
       "                  (0): LoRA(\n",
       "                    (lora_dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (mlp): MLP(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (upsample): PatchSplitting3D(\n",
       "          (lin1): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "          (lin2): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Basic3DDecoderLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0-5): 6 x Swin3DTransformerBlock(\n",
       "            (norm1): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(2, 6, 12), num_heads=8\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (lora_proj): LoRARollout(\n",
       "                (loras): ModuleList(\n",
       "                  (0): LoRA(\n",
       "                    (lora_dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (lora_qkv): LoRARollout(\n",
       "                (loras): ModuleList(\n",
       "                  (0): LoRA(\n",
       "                    (lora_dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (mlp): MLP(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Perceiver3DDecoder(\n",
       "    (level_decoder): PerceiverResampler(\n",
       "      (layers): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): PerceiverAttention(\n",
       "            (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "            (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          )\n",
       "          (1): MLP(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "              (3): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2-3): 2 x LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (surf_heads): ParameterDict(\n",
       "        (10u): Object of type: LinearPatchReconstruction\n",
       "        (10u_wave): Object of type: LinearPatchReconstruction\n",
       "        (10u_wave_density): Object of type: LinearPatchReconstruction\n",
       "        (10v): Object of type: LinearPatchReconstruction\n",
       "        (10v_wave): Object of type: LinearPatchReconstruction\n",
       "        (10v_wave_density): Object of type: LinearPatchReconstruction\n",
       "        (2t): Object of type: LinearPatchReconstruction\n",
       "        (mdts_cos): Object of type: LinearPatchReconstruction\n",
       "        (mdts_density): Object of type: LinearPatchReconstruction\n",
       "        (mdts_sin): Object of type: LinearPatchReconstruction\n",
       "        (mdww_cos): Object of type: LinearPatchReconstruction\n",
       "        (mdww_density): Object of type: LinearPatchReconstruction\n",
       "        (mdww_sin): Object of type: LinearPatchReconstruction\n",
       "        (mpts): Object of type: LinearPatchReconstruction\n",
       "        (mpts_density): Object of type: LinearPatchReconstruction\n",
       "        (mpww): Object of type: LinearPatchReconstruction\n",
       "        (mpww_density): Object of type: LinearPatchReconstruction\n",
       "        (msl): Object of type: LinearPatchReconstruction\n",
       "        (mwd1_cos): Object of type: LinearPatchReconstruction\n",
       "        (mwd1_density): Object of type: LinearPatchReconstruction\n",
       "        (mwd1_sin): Object of type: LinearPatchReconstruction\n",
       "        (mwd2_cos): Object of type: LinearPatchReconstruction\n",
       "        (mwd2_density): Object of type: LinearPatchReconstruction\n",
       "        (mwd2_sin): Object of type: LinearPatchReconstruction\n",
       "        (mwd_cos): Object of type: LinearPatchReconstruction\n",
       "        (mwd_density): Object of type: LinearPatchReconstruction\n",
       "        (mwd_sin): Object of type: LinearPatchReconstruction\n",
       "        (mwp): Object of type: LinearPatchReconstruction\n",
       "        (mwp1): Object of type: LinearPatchReconstruction\n",
       "        (mwp1_density): Object of type: LinearPatchReconstruction\n",
       "        (mwp2): Object of type: LinearPatchReconstruction\n",
       "        (mwp2_density): Object of type: LinearPatchReconstruction\n",
       "        (mwp_density): Object of type: LinearPatchReconstruction\n",
       "        (pp1d): Object of type: LinearPatchReconstruction\n",
       "        (pp1d_density): Object of type: LinearPatchReconstruction\n",
       "        (shts): Object of type: LinearPatchReconstruction\n",
       "        (shts_density): Object of type: LinearPatchReconstruction\n",
       "        (shww): Object of type: LinearPatchReconstruction\n",
       "        (shww_density): Object of type: LinearPatchReconstruction\n",
       "        (swh): Object of type: LinearPatchReconstruction\n",
       "        (swh1): Object of type: LinearPatchReconstruction\n",
       "        (swh1_density): Object of type: LinearPatchReconstruction\n",
       "        (swh2): Object of type: LinearPatchReconstruction\n",
       "        (swh2_density): Object of type: LinearPatchReconstruction\n",
       "        (swh_density): Object of type: LinearPatchReconstruction\n",
       "        (wind): Object of type: LinearPatchReconstruction\n",
       "        (wind_density): Object of type: LinearPatchReconstruction\n",
       "      (10u): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (10u_wave): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (10u_wave_density): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (10v): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (10v_wave): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (10v_wave_density): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (2t): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mdts_cos): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mdts_density): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mdts_sin): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mdww_cos): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mdww_density): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mdww_sin): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mpts): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mpts_density): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mpww): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mpww_density): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (msl): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mwd1_cos): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mwd1_density): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mwd1_sin): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mwd2_cos): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mwd2_density): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mwd2_sin): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mwd_cos): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mwd_density): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mwd_sin): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mwp): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mwp1): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mwp1_density): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mwp2): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mwp2_density): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (mwp_density): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (pp1d): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (pp1d_density): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (shts): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (shts_density): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (shww): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (shww_density): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (swh): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (swh1): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (swh1_density): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (swh2): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (swh2_density): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (swh_density): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (wind): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (wind_density): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "    )\n",
       "    (atmos_heads): ParameterDict(\n",
       "        (q): Object of type: LinearPatchReconstruction\n",
       "        (t): Object of type: LinearPatchReconstruction\n",
       "        (u): Object of type: LinearPatchReconstruction\n",
       "        (v): Object of type: LinearPatchReconstruction\n",
       "        (z): Object of type: LinearPatchReconstruction\n",
       "      (q): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (t): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (u): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (v): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "      (z): LinearPatchReconstruction(in_features=1024, out_features=16, bias=True)\n",
       "    )\n",
       "    (atmos_levels_embed): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pred = model.forward(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aurora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
